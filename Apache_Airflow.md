Apache Airflow is an open-source platform used to build, develop, and monitor workflows (pipelines).

# 📘 Guide: Apache Airflow with Docker - Initial Setup

This guide documents the step-by-step process to set up Apache Airflow using Docker Compose on Windows with WSL2.

---

## 📁 Project structure

```
AirflowDocker/
├── dags/            # Your custom DAGs go here
├── logs/            # Logs generated by Airflow
├── plugins/         # (optional) custom plugins
├── config/          # (optional) custom config like airflow.cfg
├── .env             # Contains the UID
└── docker-compose.yaml
```

---

## ✅ Prerequisites

* Install **Docker Desktop** (with WSL2 enabled)
* Update WSL:

```powershell
wsl --update
```

* Docker Desktop must be running (check 🐳 icon in the system tray)

---

## 🛠 Step 1: Create the project folder

```powershell
cd "C:\Users\...\...\..."
mkdir AirflowDocker
cd AirflowDocker
```

---

## 📥 Step 2: Download the `docker-compose.yaml` file

Download from: [https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml](https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml)

Save it as `docker-compose.yaml` inside the `AirflowDocker` folder

---

## 🧾 Step 3: Create the `.env` file

```powershell
Set-Content -Path .env -Value "AIRFLOW_UID=50000" -Encoding UTF8
```

---

## 📂 Step 4: Create required folders

```powershell
mkdir dags logs plugins config
```

---

## 🔁 Step 5: Initialize Airflow

```powershell
docker compose up airflow-init
```

This step creates:

* PostgreSQL database
* Initial configuration files
* Admin user (airflow / airflow)

---

## ▶ Step 6: Start all services

```powershell
docker compose up -d
```

---

## 🌐 Step 7: Access Airflow UI

Go to:

```
http://localhost:8080
```

Username: `airflow`
Password: `airflow`

---

## 🧪 Step 8: Test a DAG

Create a file in `dags/hello_world_dag.py`:

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def say_hello():
    print("Hello from Airflow!")

with DAG(
    dag_id="hello_airflow",
    start_date=datetime(2023, 1, 1),
    schedule_interval="@daily",
    catchup=False
) as dag:

    task1 = PythonOperator(
        task_id="print_hello",
        python_callable=say_hello
    )
```

Then go back to the browser:

1. Enable the DAG
2. Trigger manually (▶ button)
3. Check the logs

---

## 🛑 To stop all services

```powershell
docker compose down
```

---

## 🔁 Check running containers

```powershell
docker ps
```

---

## 📌 Additional notes

* Video followed: [Airflow Tutorial for Beginners](https://www.youtube.com/watch?v=K9AnJ9_ZAXE&list=PLwFJcsJ61oujAqYpMp1kdUBcPG0sE0QMT)
* GitHub repo: [coder2j/airflow-docker](https://github.com/coder2j/airflow-docker)
* Official docs: [https://airflow.apache.org/docs/apache-airflow/stable](https://airflow.apache.org/docs/apache-airflow/stable)

---

This document serves as a template for future Apache Airflow projects using Docker. It is recommended to keep it updated.
